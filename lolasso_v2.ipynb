{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-sense",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-coupon",
   "metadata": {},
   "source": [
    "Based on https://github.com/lucidrains/alphafold2 and https://github.com/lucidrains/egnn-pytorch with help from https://github.com/hypnopump."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-endorsement",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "divided-advocacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:51.852892Z",
     "start_time": "2021-04-02T16:27:51.410011Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "provincial-alexandria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:51.856022Z",
     "start_time": "2021-04-02T16:27:51.854147Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-vatican",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compact-gates",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.385781Z",
     "start_time": "2021-04-02T16:27:51.857343Z"
    }
   },
   "outputs": [],
   "source": [
    "import sidechainnet as scn\n",
    "#from sidechainnet.sequence.utils import VOCAB\n",
    "from sidechainnet.utils.sequence import ProteinVocabulary as VOCAB # From https://github.com/lucidrains/egnn-pytorch/blob/main/examples/egnn_test.ipynb\n",
    "VOCAB = VOCAB()\n",
    "from sidechainnet.structure.build_info import NUM_COORDS_PER_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ready-object",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.393212Z",
     "start_time": "2021-04-02T16:27:52.386984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v0.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "italic-spyware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.398188Z",
     "start_time": "2021-04-02T16:27:52.394118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinVocabulary[size=21]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-split",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:34.529141Z",
     "start_time": "2021-03-27T11:16:34.449068Z"
    }
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funny-tomato",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.450815Z",
     "start_time": "2021-04-02T16:27:52.399112Z"
    }
   },
   "outputs": [],
   "source": [
    "from alphafold2_pytorch import Alphafold2\n",
    "import alphafold2_pytorch.constants as constants\n",
    "\n",
    "from se3_transformer_pytorch import SE3Transformer\n",
    "from alphafold2_pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-newcastle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:34.606712Z",
     "start_time": "2021-03-27T11:16:34.599228Z"
    }
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painted-rogers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.454403Z",
     "start_time": "2021-04-02T16:27:52.451947Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = \"esm\" # one of [\"esm\", \"msa\", None]\n",
    "DEVICE = None#  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # defaults to cuda if available, else cpu\n",
    "NUM_BATCHES = int(1e5)\n",
    "GRADIENT_ACCUMULATE_EVERY = 1 #16\n",
    "LEARNING_RATE = 3e-4\n",
    "IGNORE_INDEX = -100\n",
    "THRESHOLD_LENGTH = 250\n",
    "TO_PDB = False\n",
    "SAVE_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reduced-criterion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.460549Z",
     "start_time": "2021-04-02T16:27:52.456011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('esm', None, 100000, 1, 0.0003, -100, 250, False, '')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES, DEVICE, NUM_BATCHES, GRADIENT_ACCUMULATE_EVERY, LEARNING_RATE, IGNORE_INDEX, THRESHOLD_LENGTH, TO_PDB, SAVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-chicken",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:35.274958Z",
     "start_time": "2021-03-27T11:16:35.268764Z"
    }
   },
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "average-marks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.465244Z",
     "start_time": "2021-04-02T16:27:52.461686Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = constants.DEVICE\n",
    "DISTOGRAM_BUCKETS = constants.DISTOGRAM_BUCKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "forced-grass",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:27:52.471055Z",
     "start_time": "2021-04-02T16:27:52.466277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), 37)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE, DISTOGRAM_BUCKETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-dinner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:44.738347Z",
     "start_time": "2021-03-27T11:16:35.993046Z"
    }
   },
   "source": [
    "# Set embedder model from esm if appropiate - Load ESM-1b model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "varying-mathematics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:01.414208Z",
     "start_time": "2021-04-02T16:27:52.471978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mmp/.cache/torch/hub/facebookresearch_esm_master\n"
     ]
    }
   ],
   "source": [
    "if FEATURES == \"esm\":\n",
    "    # from pytorch hub (almost 30gb)\n",
    "    embedd_model, alphabet = torch.hub.load(\"facebookresearch/esm\", \"esm1b_t33_650M_UR50S\")\n",
    "    ##  alternatively do\n",
    "    # import esm # after installing esm\n",
    "    # model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "    batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-matter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:22:10.874606Z",
     "start_time": "2021-03-27T11:22:10.869292Z"
    }
   },
   "source": [
    "# AF2 helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aggregate-collectible",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:01.417603Z",
     "start_time": "2021-04-02T16:28:01.415339Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle(loader, cond = lambda x: True):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            if not cond(data):\n",
    "                continue\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-power",
   "metadata": {},
   "source": [
    "https://github.com/jonathanking/sidechainnet#loading-sidechainnet-with-pytorch-dataloaders<br>\n",
    "`Downloaded SidechainNet to ./sidechainnet_data/sidechainnet_casp12_30.pkl.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-disposal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:48.960650Z",
     "start_time": "2021-03-27T11:16:44.744531Z"
    }
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "capital-exchange",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:06.241936Z",
     "start_time": "2021-04-02T16:28:01.418468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp12_30.pkl.\n"
     ]
    }
   ],
   "source": [
    "data = scn.load(\n",
    "    casp_version = 12,\n",
    "    thinning = 30,\n",
    "    with_pytorch = 'dataloaders',\n",
    "    batch_size = 1,\n",
    "    dynamic_batching = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceramic-image",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:06.245627Z",
     "start_time": "2021-04-02T16:28:06.243056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'train-eval', 'test', 'valid-10', 'valid-20', 'valid-30', 'valid-40', 'valid-50', 'valid-70', 'valid-90'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "foster-literacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:06.375006Z",
     "start_time": "2021-04-02T16:28:06.246678Z"
    }
   },
   "outputs": [],
   "source": [
    "data = iter(data['train'])\n",
    "data_cond = lambda t: t[1].shape[1] < THRESHOLD_LENGTH\n",
    "dl = cycle(data, data_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incoming-syndication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:06.378349Z",
     "start_time": "2021-04-02T16:28:06.376425Z"
    }
   },
   "outputs": [],
   "source": [
    "#d_test = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "little-response",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:06.388975Z",
     "start_time": "2021-04-02T16:28:06.379186Z"
    }
   },
   "outputs": [],
   "source": [
    "#dir(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "recorded-johnston",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:06.393882Z",
     "start_time": "2021-04-02T16:28:06.390143Z"
    }
   },
   "outputs": [],
   "source": [
    "# d_test \"keys\": 'angs', 'count', 'crds', 'evos', 'index', 'int_seqs',\n",
    "#                'msks', 'pids', 'ress', 'secs', 'seq_evo_sec', 'seqs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-deployment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:54.778596Z",
     "start_time": "2021-03-27T11:16:49.083056Z"
    }
   },
   "source": [
    "# AF2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "placed-abortion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:09.989924Z",
     "start_time": "2021-04-02T16:28:06.395071Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Alphafold2(\n",
    "    dim = 128,\n",
    "    depth = 1,\n",
    "    heads = 1, # Maybe set even lower?\n",
    "    dim_head = 16, # Maybe set even lower?\n",
    "    predict_coords = False,\n",
    "    num_backbone_atoms = 3,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fancy-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:09.992662Z",
     "start_time": "2021-04-02T16:28:09.991045Z"
    }
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-greenhouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:54.795251Z",
     "start_time": "2021-03-27T11:16:54.782721Z"
    }
   },
   "source": [
    "# AF2 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "northern-horror",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:10.009600Z",
     "start_time": "2021-04-02T16:28:09.993734Z"
    }
   },
   "outputs": [],
   "source": [
    "dispersion_weight = 0.1\n",
    "criterion = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-cambodia",
   "metadata": {},
   "source": [
    "# EGNN helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-radar",
   "metadata": {},
   "source": [
    "Based on: https://github.com/lucidrains/egnn-pytorch/blob/main/examples/egnn_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "possible-stocks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:10.014897Z",
     "start_time": "2021-04-02T16:28:10.010682Z"
    }
   },
   "outputs": [],
   "source": [
    "NEEDED_INFO = {\"cutoffs\": [], # \"15_closest\"\n",
    "               \"bond_scales\": [1, 2],\n",
    "               \"aa_pos_scales\": [2,4,8,16,32,64,128],\n",
    "               \"atom_pos_scales\": [1,2,4,8,16,32],\n",
    "               \"dist2ca_norm_scales\": [1,2,4],\n",
    "               \"bb_norms_atoms\": [0.5], # will encode 3 vectors with this\n",
    "               # nn-degree connection\n",
    "               \"adj_degree\": 2\n",
    "              }\n",
    "# get model sizes from encoded protein\n",
    "#seq, true_coords, angles, padding_seq, mask, id = train_examples_storer[-1] \n",
    "#NEEDED_INFO[\"seq\"] = seq[:-padding_seq or None]\n",
    "#NEEDED_INFO[\"covalent_bond\"] = prot_covalent_bond(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "elder-papua",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:10.019674Z",
     "start_time": "2021-04-02T16:28:10.017169Z"
    }
   },
   "outputs": [],
   "source": [
    "### adjust for egnn: \n",
    "#embedd_info[\"bond_n_scalars\"] -= 2*len(NEEDED_INFO[\"bond_scales\"])+1\n",
    "#embedd_info[\"bond_n_vectors\"] = 0\n",
    "#embedd_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-diameter",
   "metadata": {},
   "source": [
    "# EGNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "important-subcommittee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:10.026738Z",
     "start_time": "2021-04-02T16:28:10.020938Z"
    }
   },
   "outputs": [],
   "source": [
    "#from egnn_pytorch.egnn_pytorch import EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chief-poetry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:10.031527Z",
     "start_time": "2021-04-02T16:28:10.027888Z"
    }
   },
   "outputs": [],
   "source": [
    "os.sys.path.append('/home/mmp/projects/EleutherAI/egnn_pytorch_git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "facial-packet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:10.489248Z",
     "start_time": "2021-04-02T16:28:10.032563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoise_sparse.py  \u001b[0m\u001b[01;34megnn_pytorch_git\u001b[0m/  LICENSE    setup.cfg  \u001b[01;34mtests\u001b[0m/\r\n",
      "\u001b[01;35megnn.png\u001b[0m           \u001b[01;34mexamples\u001b[0m/          README.md  setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/mmp/projects/EleutherAI/egnn_pytorch_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "third-corps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:11.897574Z",
     "start_time": "2021-04-02T16:28:10.490581Z"
    }
   },
   "outputs": [],
   "source": [
    "from egnn_pytorch_git.egnn_pytorch_git import EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "front-coordinator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:11.906905Z",
     "start_time": "2021-04-02T16:28:11.898709Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model_egnn = EGNN_Sparse_Network(n_layers=4,\n",
    "                                 feats_dim=2,\n",
    "                                 pos_dim = 3,\n",
    "                                 edge_attr_dim = 1,\n",
    "                                 m_dim = 32,\n",
    "                                 fourier_features = 4,\n",
    "                                 embedding_nums=[36,20],\n",
    "                                 embedding_dims=[16,16],\n",
    "                                 edge_embedding_nums=[3],\n",
    "                                 edge_embedding_dims=[2],\n",
    "                                 update_coors=True,\n",
    "                                 update_feats=True, \n",
    "                                 norm_feats=False,\n",
    "                                 norm_coors=False,\n",
    "                                 recalc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "orange-stadium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:11.909732Z",
     "start_time": "2021-04-02T16:28:11.908015Z"
    }
   },
   "outputs": [],
   "source": [
    "#??EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "appreciated-march",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:11.928284Z",
     "start_time": "2021-04-02T16:28:11.910687Z"
    }
   },
   "outputs": [],
   "source": [
    "model_egnn = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "described-netherlands",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:11.942275Z",
     "start_time": "2021-04-02T16:28:11.929397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/torch/optim/adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam( list(model_egnn.parameters()) + \\\n",
    "                              list(model.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-kenya",
   "metadata": {},
   "source": [
    "# Import from geometric-vector-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "certified-newton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:11.946078Z",
     "start_time": "2021-04-02T16:28:11.943422Z"
    }
   },
   "outputs": [],
   "source": [
    "os.sys.path.append('/home/mmp/projects/EleutherAI/geometric-vector-perceptron')\n",
    "os.sys.path.append('/home/mmp/projects/EleutherAI/geometric-vector-perceptron/examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "infrared-singles",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:12.392199Z",
     "start_time": "2021-04-02T16:28:11.947174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mdiagram.png\u001b[0m  \u001b[01;34mgeometric_vector_perceptron\u001b[0m/  README.md  setup.py\r\n",
      "\u001b[01;34mexamples\u001b[0m/    LICENSE                       setup.cfg  \u001b[01;34mtests\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/mmp/projects/EleutherAI/geometric-vector-perceptron/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "enhanced-spain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:12.408561Z",
     "start_time": "2021-04-02T16:28:12.393522Z"
    }
   },
   "outputs": [],
   "source": [
    "from examples.data_utils import encode_whole_protein, prot_covalent_bond, encode_whole_bonds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-officer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T19:19:56.343261Z",
     "start_time": "2021-03-27T19:19:55.635175Z"
    }
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bridal-brook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:12.411506Z",
     "start_time": "2021-04-02T16:28:12.409653Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fancy-survival",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:12.416598Z",
     "start_time": "2021-04-02T16:28:12.412431Z"
    }
   },
   "outputs": [],
   "source": [
    "#from alphafold2_pytorch.utils import get_esm_embedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "documented-journal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:12.422700Z",
     "start_time": "2021-04-02T16:28:12.417664Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_esm_embedd_TEST(seq, embedd_model, batch_converter, embedd_type=\"per_tok\"):\n",
    "    \"\"\" Returns the ESM embeddings for a protein. \n",
    "        Inputs: \n",
    "        * seq: (L,) tensor of ints (in sidechainnet int-char convention)\n",
    "        * embedd_model: ESM model (see train_end2end.py for an example)\n",
    "        * batch_converter: ESM batch converter (see train_end2end.py for an example)\n",
    "        * embedd_type: one of [\"mean\", \"per_tok\"]. \n",
    "                       \"per_tok\" is recommended if working with sequences.\n",
    "    \"\"\"\n",
    "    str_seq = \"\".join([VOCAB._int2char[x]for x in seq.cpu().numpy()])\n",
    "    print(f\"len(str_seq): {len(str_seq)}\")\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter( [(0, str_seq)] )\n",
    "    print(f\"len(batch_labels): {len(batch_labels)}\")\n",
    "    print(f\"len(batch_strs): {len(batch_strs)}\")\n",
    "    with torch.no_grad():\n",
    "        results = embedd_model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "        print(f\"results.keys(): {results.keys()}\")\n",
    "        print(f\"results['representations'][33].shape: {results['representations'][33].shape}\")\n",
    "    # index 0 is for start token. so take from 1 one\n",
    "    print(f\"len(str_seq) + 1: {len(str_seq) + 1}\")\n",
    "    #pdb.set_trace()\n",
    "    token_reps = results['representations'][33][:, 1 : len(str_seq) + 1].to(seq.device)\n",
    "    if embedd_type == \"mean\":\n",
    "        token_reps = token_reps.mean(dim=0)\n",
    "    print(f\"token_reps.shape: {token_reps.shape}\")\n",
    "    return token_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "strategic-philip",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:28:16.334557Z",
     "start_time": "2021-04-02T16:28:12.423903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq.shape: torch.Size([1, 185]), type(embedd_model) <class 'esm.model.ProteinBertModel'>, type(batch_converter) <class 'esm.data.BatchConverter'>\n",
      "len(str_seq): 185\n",
      "len(batch_labels): 1\n",
      "len(batch_strs): 1\n",
      "results.keys(): dict_keys(['logits', 'representations'])\n",
      "results['representations'][33].shape: torch.Size([1, 187, 1280])\n",
      "len(str_seq) + 1: 186\n",
      "token_reps.shape: torch.Size([1, 185, 1280])\n",
      "embedds.shape: torch.Size([1, 1, 185, 1280])\n",
      "it: 0, stress tensor([256715.1250], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 1, stress tensor([307274.5625], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "breaking at iteration 1 with stress tensor([97526.3828], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Corrected mirror idxs: tensor([0])\n",
      "len(seq_str): 185, pred_coords.shape: torch.Size([1, 2590, 3]), angles.shape: torch.Size([1, 185, 12]), padding_seq: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4bba39875413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"len(seq_str): {len(seq_str)}, pred_coords.shape: {pred_coords.shape}, angles.shape: {angles.shape}, padding_seq: {padding_seq}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_whole_protein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeded_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEEDED_INFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_mem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/EleutherAI/geometric-vector-perceptron/examples/data_utils.py\u001b[0m in \u001b[0;36mencode_whole_protein\u001b[0;34m(seq, true_coords, angles, padding_seq, needed_info, free_mem)\u001b[0m\n\u001b[1;32m    563\u001b[0m                                    \u001b[0mx_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"coords\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                                    \u001b[0membedd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                                    needed_info = needed_info )\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0mwhole_bond_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhole_bond_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbond_embedd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbond_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;31m#########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/EleutherAI/geometric-vector-perceptron/examples/data_utils.py\u001b[0m in \u001b[0;36mencode_whole_bonds\u001b[0;34m(x, x_format, embedd_info, needed_info, free_mem, eps)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mneeded_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"adj_degree\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mnative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mnative_bonds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mprot_covalent_bond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeded_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeded_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"adj_degree\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'seq'"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "baseline_losses = []\n",
    "\n",
    "for _ in range(NUM_BATCHES):\n",
    "    for _ in range(GRADIENT_ACCUMULATE_EVERY):\n",
    "        \n",
    "        ### Stage 1\n",
    "        \n",
    "        batch = next(dl)\n",
    "        seq, coords, mask = batch.seqs, batch.crds, batch.msks\n",
    "        mask = mask.bool() # Needs to be set to bool\n",
    "\n",
    "        b, l, _ = seq.shape\n",
    "\n",
    "        # prepare data and mask labels\n",
    "        seq, coords, mask = seq.argmax(dim = -1).to(DEVICE), coords.to(DEVICE), mask.to(DEVICE)\n",
    "\n",
    "        # sequence embedding (msa / esm / attn / or nothing)\n",
    "        msa, embedds = None, None\n",
    "\n",
    "        # get embedds\n",
    "        if FEATURES == \"esm\":\n",
    "            print(f\"seq.shape: {seq.shape}, type(embedd_model) {type(embedd_model)}, type(batch_converter) {type(batch_converter)}\")\n",
    "            #embedds = get_esm_embedd(seq, embedd_model, batch_converter, embedd_type=\"per_tok\").unsqueeze(0)\n",
    "            embedds = get_esm_embedd_TEST(seq[0], embedd_model, batch_converter, embedd_type=\"per_tok\").unsqueeze(0)\n",
    "            print(f\"embedds.shape: {embedds.shape}\")\n",
    "            #pdb.set_trace()\n",
    "            msa_mask = None\n",
    "            #msa_mask = torch.ones_like(embedds).bool()\n",
    "            #msa_mask = torch.ones_like(embedds[..., -1]).bool()\n",
    "        # get msa here\n",
    "        elif FEATURES == \"msa\":\n",
    "            pass\n",
    "        # no embeddings\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # predict - out is (batch, L * 3, 3)\n",
    "\n",
    "        distogram = model(\n",
    "            seq,\n",
    "            msa = msa,\n",
    "            embedds = embedds,\n",
    "            mask = mask,\n",
    "            msa_mask = msa_mask\n",
    "            )\n",
    "        \n",
    "        ### Stage 2 - get 3d structure\n",
    "        \n",
    "        assert model.num_backbone_atoms > 1, 'must constitute to at least 3 atomic coordinates for backbone'\n",
    "\n",
    "\n",
    "        N_mask, CA_mask, C_mask = scn_backbone_mask(seq, boolean = True, n_aa = model.num_backbone_atoms)\n",
    "\n",
    "        cloud_mask = scn_cloud_mask(seq, boolean = True)\n",
    "        chain_mask = (mask.unsqueeze(-1) * cloud_mask)\n",
    "        \n",
    "        bb_flat_mask = rearrange(chain_mask[..., :model.num_backbone_atoms], 'b l c -> b (l c)')\n",
    "        bb_flat_mask_crossed = rearrange(bb_flat_mask, 'b i -> b i ()') * rearrange(bb_flat_mask, 'b j -> b () j')\n",
    "\n",
    "        # structural refinement\n",
    "\n",
    "        if model.predict_real_value_distances:\n",
    "            distances, distance_std = distogram.unbind(dim = -1)\n",
    "            weights = (1 / (1 + distance_std)) # could also do a distance_std.sigmoid() here\n",
    "        else:\n",
    "            distances, weights = center_distogram_torch(distogram)\n",
    "\n",
    "        # set unwanted atoms to weight=0 (like C-beta in glycine)\n",
    "        weights.masked_fill_( torch.logical_not(bb_flat_mask_crossed), 0.)\n",
    "\n",
    "        coords_3d, _ = MDScaling(distances, \n",
    "            weights = weights,\n",
    "            iters = model.mds_iters,\n",
    "            fix_mirror = True,\n",
    "            N_mask = N_mask,\n",
    "            CA_mask = CA_mask,\n",
    "            C_mask = C_mask\n",
    "        )\n",
    "        \n",
    "        pred_coords = rearrange(coords_3d, 'b c n -> b n c')\n",
    "        \n",
    "        #Â add sidechain\n",
    "        pred_coords = sidechain_container(pred_coords, n_aa = model.num_backbone_atoms, cloud_mask=cloud_mask)\n",
    "        pred_coords = rearrange(pred_coords, 'b n l d -> b (n l) d')\n",
    "        \n",
    "        ### Stage 3 - refinement        \n",
    "        \n",
    "        # We need as shown in line:\n",
    "        # seq, true_coords, angles, padding_seq, mask, pid = get_prot(dataloader_=dataloaders_,\n",
    "        \n",
    "        # From batch \"keys\":\n",
    "        # 'angs', 'count', 'crds', 'evos', 'index', 'int_seqs', 'msks', 'pids', 'ress', 'secs', 'seq_evo_sec', 'seqs'\n",
    "        \n",
    "        # Assume batch dim is 1\n",
    "        true_coords = coords # get the coords label from above\n",
    "        angles = batch.angs.to(DEVICE)\n",
    "        seq_str = ''.join([VOCAB.int2char(aa.item()) for aa in seq[0]])\n",
    "        padding_seq = (seq[0] == 20).sum()\n",
    "        mask = batch.msks.to(DEVICE)\n",
    "        pid = batch.pids #.to(DEVICE)\n",
    "        \n",
    "        # encode as needed\n",
    "        \n",
    "        print(f\"len(seq_str): {len(seq_str)}, pred_coords.shape: {pred_coords.shape}, angles.shape: {angles.shape}, padding_seq: {padding_seq}\")\n",
    "        encoded = encode_whole_protein(seq_str, true_coords[0], angles[0], padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        x, edge_index, edge_attrs, embedd_info = encoded\n",
    "        \n",
    "        # add position coords - better mask accounting for missing atoms\n",
    "        cloud_mask_naive = scn_cloud_mask(seq_str).bool()\n",
    "        cloud_mask = scn_cloud_mask(seq_str, coords=true_coords).bool()\n",
    "        if padding_seq:\n",
    "            cloud_mask[-padding_seq:] = 0.\n",
    "        # cloud is all points, chain is all for which we have labels\n",
    "        chain_mask = mask.unsqueeze(-1) * cloud_mask\n",
    "        flat_chain_mask = rearrange(chain_mask, 'l c -> (l c)')\n",
    "        flat_cloud_mask = rearrange(cloud_mask, 'l c -> (l c)')\n",
    "        # slice useless norm and vector embeddings\n",
    "        masked_coords = true_coords[flat_cloud_mask]\n",
    "\n",
    "        #############\n",
    "        # MASK EDGES AND NODES ACCOUNTING FOR SCN MISSING ATOMS\n",
    "        #############\n",
    "        # NODES\n",
    "        x = torch.cat([masked_coords, x[:, -2:][cloud_mask[cloud_mask_naive]] ], dim=-1)\n",
    "        # EDGES: delete all edges with masked-out atoms\n",
    "\n",
    "        # pick all current indexes and turn them to 1.\n",
    "        to_mask_edges = torch.zeros(edge_index.amax()+1, edge_index.amax()+1).to(edge_index.device)\n",
    "        to_mask_edges[edge_index[0], edge_index[1]] = 1.\n",
    "        # delete erased bonds\n",
    "        masked_out_atoms = (-1*(cloud_mask[cloud_mask_naive].float() - 1)).bool()\n",
    "        to_mask_edges[masked_out_atoms] *= 0.\n",
    "        to_mask_edges = to_mask_edges * to_mask_edges.t()\n",
    "        # get mask for the edge_attrs\n",
    "        attr_mask = to_mask_edges[edge_index[0], edge_index[1]].bool()\n",
    "        edge_attrs = edge_attrs[attr_mask, :]\n",
    "        # delete unwanted rows and cols\n",
    "        wanted = to_mask_edges.sum(dim=-1).bool()\n",
    "        edge_index = (to_mask_edges[wanted, :][:, wanted]).nonzero().t()\n",
    "        #############\n",
    "        # continue\n",
    "        #############\n",
    "        edge_attrs = edge_attrs[:, -1:]\n",
    "        batch = torch.tensor([0 for i in range(x.shape[0])], device=DEVICE).long()\n",
    "\n",
    "        if torch.amax(edge_index) >= x.shape[0]:\n",
    "            print(\"wtf, breaking, debug, index out of bounds\")\n",
    "            break\n",
    "\n",
    "        # predict\n",
    "        preds = model.forward(x, edge_index, batch=batch, edge_attr=edge_attrs,\n",
    "                              recalc_edge=None, verbose = False)\n",
    "\n",
    "        # MEASURE ERROR - format pred and target\n",
    "        target_coords = true_coords[flat_cloud_mask].clone()\n",
    "        bae_coords    = x[:, :3]\n",
    "        pred_coords   = preds[:, :3]\n",
    "\n",
    "        # option 2: loss is RMSD on reconstructed coords  // align - sometimes svc fails - idk why\n",
    "        try:\n",
    "            pred_aligned, target_aligned = kabsch_torch(pred_coords.t(), target_coords.t()) # (3, N)\n",
    "            base_aligned, _              = kabsch_torch(base_coords.t(), target_coords.t()) # (3, N)\n",
    "\n",
    "            loss = ( (pred_aligned.t() - target_aligned.t())[flat_chain_mask[flat_cloud_mask]]**2 ).mean() \n",
    "            loss_base = ( (base_aligned.t() - target_aligned.t())[flat_chain_mask[flat_cloud_mask]]**2 ).mean()\n",
    "        except:\n",
    "            base_aligned, pred_aligned, target_aligned = None, None, None\n",
    "            print(\"svd failed convergence, ep:\", ep)\n",
    "            loss = ( (pred_coords - target_coords)[flat_chain_mask[flat_cloud_mask]]**2 ).mean()\n",
    "            loss_base = ( (base_coords - target_coords)[flat_chain_mask[flat_cloud_mask]]**2 ).mean()\n",
    "\n",
    "        # back pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # records / prints\n",
    "        iteration += 1\n",
    "        epoch_losses.append( loss.item() )\n",
    "        baseline_losses.append( loss_base.item() )\n",
    "\n",
    "        n_print = 10\n",
    "        if iteration % n_print == 1:\n",
    "            tic = time.time()\n",
    "            print(\"BATCH: {0} / {1}, loss: {2}, baseline_loss: {3}, time: {4}\".format(iteration, n_per_iter,\n",
    "                                                                                      np.mean(epoch_losses[-n_print:]),\n",
    "                                                                                      np.mean(baseline_losses[-n_print:]),\n",
    "                                                                                      tic-tac))\n",
    "            tac = time.time()\n",
    "            if iteration % n_per_iter == 1:\n",
    "                print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-stadium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T16:29:54.881153Z",
     "start_time": "2021-04-02T16:29:38.140863Z"
    }
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "preceding-mexican",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:00:49.348668Z",
     "start_time": "2021-04-02T10:00:49.343111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.214285714285715"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "633/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-there",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spatial-wound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:58.860910Z",
     "start_time": "2021-03-30T19:15:58.783068Z"
    }
   },
   "outputs": [],
   "source": [
    "??Alphafold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "substantial-aurora",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:42.262755Z",
     "start_time": "2021-03-30T19:15:42.257525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alphafold2_pytorch.alphafold2.Alphafold2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acoustic-consistency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:29.356150Z",
     "start_time": "2021-03-30T19:15:29.350419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_backbone_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-growth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:58:04.574746Z",
     "start_time": "2021-03-30T18:57:44.749Z"
    }
   },
   "outputs": [],
   "source": [
    "        ### Old stuff:\n",
    "\n",
    "#        # build SC container. set SC points to CA and optionally place carbonyl O\n",
    "#        proto_sidechain = sidechain_container(refined, n_aa=batch,\n",
    "#                                              cloud_mask=cloud_mask, place_oxygen=False)\n",
    "#\n",
    "#        # rotate / align\n",
    "#        coords_aligned, labels_aligned = Kabsch(refined, coords[flat_cloud_mask])\n",
    "#\n",
    "#        # atom mask\n",
    "#\n",
    "#        cloud_mask = scn_cloud_mask(seq, boolean = False)\n",
    "#        flat_cloud_mask = rearrange(cloud_mask, 'b l c -> b (l c)')\n",
    "#\n",
    "#        # chain_mask is all atoms that will be backpropped thru -> existing + trainable\n",
    "#\n",
    "#        chain_mask = (mask * cloud_mask)[cloud_mask]\n",
    "#        flat_chain_mask = rearrange(chain_mask, 'b l c -> b (l c)')\n",
    "#\n",
    "#        # save pdb files for visualization\n",
    "#\n",
    "#        if TO_PDB:\n",
    "#            # idx from batch to save prot and label\n",
    "#            idx = 0\n",
    "#            coords2pdb(seq[idx, :, 0], coords_aligned[idx], cloud_mask, prefix=SAVE_DIR, name=\"pred.pdb\")\n",
    "#            coords2pdb(seq[idx, :, 0], labels_aligned[idx], cloud_mask, prefix=SAVE_DIR, name=\"label.pdb\")\n",
    "#\n",
    "#        # loss - RMSE + distogram_dispersion\n",
    "#        loss = torch.sqrt(criterion(coords_aligned[flat_chain_mask], labels_aligned[flat_chain_mask])) + \\\n",
    "#                          dispersion_weight * torch.norm( (1/weights)-1 )\n",
    "#\n",
    "#        loss.backward()\n",
    "#    print('loss:', loss.item())\n",
    "#\n",
    "#    optim.step()\n",
    "#    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-provincial",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphafold2_pytorch",
   "language": "python",
   "name": "alphafold2_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
