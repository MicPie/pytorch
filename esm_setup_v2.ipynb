{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-sense",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-coupon",
   "metadata": {},
   "source": [
    "Based on https://github.com/lucidrains/alphafold2 and https://github.com/lucidrains/egnn-pytorch with help from https://github.com/hypnopump."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-endorsement",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "divided-advocacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.334370Z",
     "start_time": "2021-04-02T10:44:42.977625Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "provincial-alexandria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.337521Z",
     "start_time": "2021-04-02T10:44:43.335598Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-vatican",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compact-gates",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.777928Z",
     "start_time": "2021-04-02T10:44:43.338870Z"
    }
   },
   "outputs": [],
   "source": [
    "import sidechainnet as scn\n",
    "#from sidechainnet.sequence.utils import VOCAB\n",
    "from sidechainnet.utils.sequence import ProteinVocabulary as VOCAB # From https://github.com/lucidrains/egnn-pytorch/blob/main/examples/egnn_test.ipynb\n",
    "VOCAB = VOCAB()\n",
    "from sidechainnet.structure.build_info import NUM_COORDS_PER_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italic-spyware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.791698Z",
     "start_time": "2021-04-02T10:44:43.780853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinVocabulary[size=21]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-split",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:34.529141Z",
     "start_time": "2021-03-27T11:16:34.449068Z"
    }
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funny-tomato",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.855130Z",
     "start_time": "2021-04-02T10:44:43.793148Z"
    }
   },
   "outputs": [],
   "source": [
    "from alphafold2_pytorch import Alphafold2\n",
    "import alphafold2_pytorch.constants as constants\n",
    "\n",
    "from se3_transformer_pytorch import SE3Transformer\n",
    "from alphafold2_pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-newcastle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:34.606712Z",
     "start_time": "2021-03-27T11:16:34.599228Z"
    }
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painted-rogers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.858646Z",
     "start_time": "2021-04-02T10:44:43.856179Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = \"esm\" # one of [\"esm\", \"msa\", None]\n",
    "DEVICE = None # defaults to cuda if available, else cpu\n",
    "NUM_BATCHES = int(1e5)\n",
    "GRADIENT_ACCUMULATE_EVERY = 1 #16\n",
    "LEARNING_RATE = 3e-4\n",
    "IGNORE_INDEX = -100\n",
    "THRESHOLD_LENGTH = 250\n",
    "TO_PDB = False\n",
    "SAVE_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reduced-criterion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.864602Z",
     "start_time": "2021-04-02T10:44:43.859618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('esm', None, 100000, 1, 0.0003, -100, 250, False, '')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES, DEVICE, NUM_BATCHES, GRADIENT_ACCUMULATE_EVERY, LEARNING_RATE, IGNORE_INDEX, THRESHOLD_LENGTH, TO_PDB, SAVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-chicken",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:35.274958Z",
     "start_time": "2021-03-27T11:16:35.268764Z"
    }
   },
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "average-marks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.869245Z",
     "start_time": "2021-04-02T10:44:43.865539Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = constants.DEVICE\n",
    "DISTOGRAM_BUCKETS = constants.DISTOGRAM_BUCKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forced-grass",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:43.874652Z",
     "start_time": "2021-04-02T10:44:43.871034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE, DISTOGRAM_BUCKETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-dinner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:44.738347Z",
     "start_time": "2021-03-27T11:16:35.993046Z"
    }
   },
   "source": [
    "# Set embedder model from esm if appropiate - Load ESM-1b model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "varying-mathematics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:51.784976Z",
     "start_time": "2021-04-02T10:44:43.875829Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mmp/.cache/torch/hub/facebookresearch_esm_master\n"
     ]
    }
   ],
   "source": [
    "if FEATURES == \"esm\":\n",
    "    # from pytorch hub (almost 30gb)\n",
    "    embedd_model, alphabet = torch.hub.load(\"facebookresearch/esm\", \"esm1b_t33_650M_UR50S\")\n",
    "    ##  alternatively do\n",
    "    # import esm # after installing esm\n",
    "    # model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "    batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-matter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:22:10.874606Z",
     "start_time": "2021-03-27T11:22:10.869292Z"
    }
   },
   "source": [
    "# AF2 helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggregate-collectible",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:51.789994Z",
     "start_time": "2021-04-02T10:44:51.786113Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle(loader, cond = lambda x: True):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            if not cond(data):\n",
    "                continue\n",
    "            yield data\n",
    "\n",
    "def get_esm_embedd(seq):\n",
    "    str_seq = \"\".join([VOCAB.int2char(x) for x in seq.squeeze(0).cpu().numpy()])\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter( [(0, str_seq)] )\n",
    "    with torch.no_grad():\n",
    "        results = embedd_model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    return results[\"representations\"][33].to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-power",
   "metadata": {},
   "source": [
    "https://github.com/jonathanking/sidechainnet#loading-sidechainnet-with-pytorch-dataloaders<br>\n",
    "`Downloaded SidechainNet to ./sidechainnet_data/sidechainnet_casp12_30.pkl.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-disposal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:48.960650Z",
     "start_time": "2021-03-27T11:16:44.744531Z"
    }
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "capital-exchange",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:55.966135Z",
     "start_time": "2021-04-02T10:44:51.790974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp12_30.pkl.\n"
     ]
    }
   ],
   "source": [
    "data = scn.load(\n",
    "    casp_version = 12,\n",
    "    thinning = 30,\n",
    "    with_pytorch = 'dataloaders',\n",
    "    batch_size = 1,\n",
    "    dynamic_batching = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceramic-image",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:55.969862Z",
     "start_time": "2021-04-02T10:44:55.967274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'train-eval', 'test', 'valid-10', 'valid-20', 'valid-30', 'valid-40', 'valid-50', 'valid-70', 'valid-90'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "foster-literacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:56.093622Z",
     "start_time": "2021-04-02T10:44:55.970866Z"
    }
   },
   "outputs": [],
   "source": [
    "data = iter(data['train'])\n",
    "data_cond = lambda t: t[1].shape[1] < THRESHOLD_LENGTH\n",
    "dl = cycle(data, data_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incoming-syndication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:56.097105Z",
     "start_time": "2021-04-02T10:44:56.094983Z"
    }
   },
   "outputs": [],
   "source": [
    "#d_test = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "little-response",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:56.107573Z",
     "start_time": "2021-04-02T10:44:56.098389Z"
    }
   },
   "outputs": [],
   "source": [
    "#dir(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recorded-johnston",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:56.112233Z",
     "start_time": "2021-04-02T10:44:56.108718Z"
    }
   },
   "outputs": [],
   "source": [
    "# d_test \"keys\": 'angs', 'count', 'crds', 'evos', 'index', 'int_seqs',\n",
    "#                'msks', 'pids', 'ress', 'secs', 'seq_evo_sec', 'seqs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-deployment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:54.778596Z",
     "start_time": "2021-03-27T11:16:49.083056Z"
    }
   },
   "source": [
    "# AF2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "placed-abortion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.339512Z",
     "start_time": "2021-04-02T10:44:56.113254Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Alphafold2(\n",
    "    dim = 128,\n",
    "    depth = 1,\n",
    "    heads = 1, # Maybe set even lower?\n",
    "    dim_head = 16, # Maybe set even lower?\n",
    "    predict_coords = False,\n",
    "    num_backbone_atoms = 3,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fancy-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.342407Z",
     "start_time": "2021-04-02T10:44:59.340636Z"
    }
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-greenhouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:54.795251Z",
     "start_time": "2021-03-27T11:16:54.782721Z"
    }
   },
   "source": [
    "# AF2 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "northern-horror",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.359612Z",
     "start_time": "2021-04-02T10:44:59.343373Z"
    }
   },
   "outputs": [],
   "source": [
    "dispersion_weight = 0.1\n",
    "criterion = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-cambodia",
   "metadata": {},
   "source": [
    "# EGNN helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-radar",
   "metadata": {},
   "source": [
    "Based on: https://github.com/lucidrains/egnn-pytorch/blob/main/examples/egnn_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "possible-stocks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.364368Z",
     "start_time": "2021-04-02T10:44:59.360631Z"
    }
   },
   "outputs": [],
   "source": [
    "NEEDED_INFO = {\"cutoffs\": [], # \"15_closest\"\n",
    "               \"bond_scales\": [1, 2],\n",
    "               \"aa_pos_scales\": [2,4,8,16,32,64,128],\n",
    "               \"atom_pos_scales\": [1,2,4,8,16,32],\n",
    "               \"dist2ca_norm_scales\": [1,2,4],\n",
    "               \"bb_norms_atoms\": [0.5], # will encode 3 vectors with this\n",
    "               # nn-degree connection\n",
    "               \"adj_degree\": 2\n",
    "              }\n",
    "# get model sizes from encoded protein\n",
    "#seq, true_coords, angles, padding_seq, mask, id = train_examples_storer[-1] \n",
    "#NEEDED_INFO[\"seq\"] = seq[:-padding_seq or None]\n",
    "#NEEDED_INFO[\"covalent_bond\"] = prot_covalent_bond(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elder-papua",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.371433Z",
     "start_time": "2021-04-02T10:44:59.365423Z"
    }
   },
   "outputs": [],
   "source": [
    "### adjust for egnn: \n",
    "#embedd_info[\"bond_n_scalars\"] -= 2*len(NEEDED_INFO[\"bond_scales\"])+1\n",
    "#embedd_info[\"bond_n_vectors\"] = 0\n",
    "#embedd_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-diameter",
   "metadata": {},
   "source": [
    "# EGNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "important-subcommittee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.376085Z",
     "start_time": "2021-04-02T10:44:59.372399Z"
    }
   },
   "outputs": [],
   "source": [
    "#from egnn_pytorch.egnn_pytorch import EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "chief-poetry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.381063Z",
     "start_time": "2021-04-02T10:44:59.377133Z"
    }
   },
   "outputs": [],
   "source": [
    "os.sys.path.append('/home/mmp/projects/EleutherAI/egnn_pytorch_git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "facial-packet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:44:59.850224Z",
     "start_time": "2021-04-02T10:44:59.382259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoise_sparse.py  \u001b[0m\u001b[01;34megnn_pytorch_git\u001b[0m/  LICENSE    setup.cfg  \u001b[01;34mtests\u001b[0m/\r\n",
      "\u001b[01;35megnn.png\u001b[0m           \u001b[01;34mexamples\u001b[0m/          README.md  setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/mmp/projects/EleutherAI/egnn_pytorch_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "third-corps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.122971Z",
     "start_time": "2021-04-02T10:44:59.855823Z"
    }
   },
   "outputs": [],
   "source": [
    "from egnn_pytorch_git.egnn_pytorch_git import EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "front-coordinator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.133050Z",
     "start_time": "2021-04-02T10:45:01.125155Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model_egnn = EGNN_Sparse_Network(n_layers=4,\n",
    "                                 feats_dim=2,\n",
    "                                 pos_dim = 3,\n",
    "                                 edge_attr_dim = 1,\n",
    "                                 m_dim = 32,\n",
    "                                 fourier_features = 4,\n",
    "                                 embedding_nums=[36,20],\n",
    "                                 embedding_dims=[16,16],\n",
    "                                 edge_embedding_nums=[3],\n",
    "                                 edge_embedding_dims=[2],\n",
    "                                 update_coors=True,\n",
    "                                 update_feats=True, \n",
    "                                 norm_feats=False,\n",
    "                                 norm_coors=False,\n",
    "                                 recalc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "orange-stadium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.135824Z",
     "start_time": "2021-04-02T10:45:01.134250Z"
    }
   },
   "outputs": [],
   "source": [
    "#??EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "appreciated-march",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.153800Z",
     "start_time": "2021-04-02T10:45:01.136810Z"
    }
   },
   "outputs": [],
   "source": [
    "model_egnn = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "described-netherlands",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.167232Z",
     "start_time": "2021-04-02T10:45:01.154802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/torch/optim/adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam( list(model_egnn.parameters()) + \\\n",
    "                              list(model.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-kenya",
   "metadata": {},
   "source": [
    "# Import from geometric-vector-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "certified-newton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.174065Z",
     "start_time": "2021-04-02T10:45:01.168166Z"
    }
   },
   "outputs": [],
   "source": [
    "os.sys.path.append('/home/mmp/projects/EleutherAI/geometric-vector-perceptron')\n",
    "os.sys.path.append('/home/mmp/projects/EleutherAI/geometric-vector-perceptron/examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "infrared-singles",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.614479Z",
     "start_time": "2021-04-02T10:45:01.175052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mdiagram.png\u001b[0m  \u001b[01;34mgeometric_vector_perceptron\u001b[0m/  README.md  setup.py\r\n",
      "\u001b[01;34mexamples\u001b[0m/    LICENSE                       setup.cfg  \u001b[01;34mtests\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/mmp/projects/EleutherAI/geometric-vector-perceptron/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "enhanced-spain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:45:01.638830Z",
     "start_time": "2021-04-02T10:45:01.620292Z"
    }
   },
   "outputs": [],
   "source": [
    "from examples.data_utils import encode_whole_protein, prot_covalent_bond, encode_whole_bonds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-officer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T19:19:56.343261Z",
     "start_time": "2021-03-27T19:19:55.635175Z"
    }
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bridal-brook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:46:49.479733Z",
     "start_time": "2021-04-02T10:46:49.473880Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "strategic-philip",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:56:20.249040Z",
     "start_time": "2021-04-02T10:56:19.615266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0, stress tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 1, stress tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 2, stress tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 3, stress tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 4, stress tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Corrected mirror idxs: tensor([0])\n",
      "len(seq_str): 156, pred_coords.shape: torch.Size([1, 468, 3]), angles.shape: torch.Size([1, 156, 12]), padding_seq: 0\n"
     ]
    },
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"(l c) d -> l c d\".\n Input tensor shape: torch.Size([468, 3]). Additional info: {'c': 14}.\n Shape mismatch, can't divide axis of length 468 in chunks of 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mrecipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_transformation_recipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashable_axes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEinopsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    204\u001b[0m         init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes = self.reconstruct_from_shape(\n\u001b[0;32m--> 205\u001b[0;31m             backend.shape(tensor))\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreconstruct_from_shape\u001b[0;34m(self, shape, optimize)\u001b[0m\n\u001b[1;32m    175\u001b[0m                         raise EinopsError(\"Shape mismatch, can't divide axis of length {} in chunks of {}\".format(\n\u001b[0;32m--> 176\u001b[0;31m                             length, known_product))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEinopsError\u001b[0m: Shape mismatch, can't divide axis of length 468 in chunks of 14",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0de389ebb683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"len(seq_str): {len(seq_str)}, pred_coords.shape: {pred_coords.shape}, angles.shape: {angles.shape}, padding_seq: {padding_seq}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_whole_protein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeded_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEEDED_INFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_mem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/EleutherAI/geometric-vector-perceptron/examples/data_utils.py\u001b[0m in \u001b[0;36mencode_whole_protein\u001b[0;34m(seq, true_coords, angles, padding_seq, needed_info, free_mem)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0mpos_unit_norms_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_unit_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneeded_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"atom_pos_scales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# reformat coordinates to scn (L, 14, 3) - TODO: solve if padding=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m     \u001b[0mcoords_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(l c) d -> l c d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpadding_seq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;31m# position in backbone embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rearrange can't be applied to an empty list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_on_zeroth_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rearrange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n Input is list. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'Additional info: {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"(l c) d -> l c d\".\n Input tensor shape: torch.Size([468, 3]). Additional info: {'c': 14}.\n Shape mismatch, can't divide axis of length 468 in chunks of 14"
     ]
    }
   ],
   "source": [
    "for _ in range(NUM_BATCHES):\n",
    "    for _ in range(GRADIENT_ACCUMULATE_EVERY):\n",
    "        \n",
    "        ### Stage 1\n",
    "        \n",
    "        batch = next(dl)\n",
    "        seq, coords, mask = batch.seqs, batch.crds, batch.msks\n",
    "        mask = mask.bool() # Needs to be set to bool\n",
    "\n",
    "        b, l, _ = seq.shape\n",
    "\n",
    "        # prepare data and mask labels\n",
    "        seq, coords, mask = seq.argmax(dim = -1).to(DEVICE), coords.to(DEVICE), mask.to(DEVICE)\n",
    "        # coords = rearrange(coords, 'b (l c) d -> b l c d', l = l) # no need to rearrange for now\n",
    "        # mask the atoms and backbone positions for each residue\n",
    "\n",
    "        # sequence embedding (msa / esm / attn / or nothing)\n",
    "        msa, embedds = None, None\n",
    "\n",
    "        # get embedds\n",
    "        if FEATURES == \"esm\":\n",
    "            #embedds = get_esm_embedd(seq)\n",
    "            embedds = get_esm_embedd(seq).unsqueeze(0)\n",
    "            msa_mask = None\n",
    "            #msa_mask = torch.ones_like(embedds).bool()\n",
    "            #msa_mask = torch.ones_like(embedds[..., -1]).bool()\n",
    "        # get msa here\n",
    "        elif FEATURES == \"msa\":\n",
    "            pass\n",
    "        # no embeddings\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # predict - out is (batch, L * 3, 3)\n",
    "\n",
    "        refined = model(\n",
    "            seq,\n",
    "            msa = msa,\n",
    "            embedds = embedds,\n",
    "            mask = mask,\n",
    "            msa_mask = msa_mask\n",
    "            )\n",
    "        \n",
    "        ### Stage 2\n",
    "        \n",
    "        distance_pred = refined # is this correct?\n",
    "        \n",
    "        \n",
    "        # prepare mask for backbone coordinates\n",
    "\n",
    "        assert model.num_backbone_atoms > 1, 'must constitute to at least 3 atomic coordinates for backbone'\n",
    "\n",
    "        N_mask, CA_mask, C_mask = scn_backbone_mask(seq, boolean = True, n_aa = model.num_backbone_atoms)\n",
    "\n",
    "        cloud_mask = scn_cloud_mask(seq, boolean=True)\n",
    "        flat_cloud_mask = rearrange(cloud_mask, 'b l c -> b (l c)')\n",
    "        chain_mask = (mask.unsqueeze(-1) * cloud_mask)\n",
    "        flat_chain_mask = rearrange(chain_mask, 'b l c -> b (l c)')\n",
    "\n",
    "        bb_mask = rearrange(chain_mask[:, :, :model.num_backbone_atoms], 'b l c -> b (l c)')\n",
    "        bb_mask_crossed = rearrange(bb_mask, 'b i -> b i ()') * rearrange(bb_mask, 'b j -> b () j')\n",
    "\n",
    "        # structural refinement\n",
    "\n",
    "        if model.predict_real_value_distances:\n",
    "            distances, distance_std = distance_pred.unbind(dim = -1)\n",
    "            weights = (1 / (1 + distance_std)) # could also do a distance_std.sigmoid() here\n",
    "        else:\n",
    "            distances, weights = center_distogram_torch(distance_pred)\n",
    "\n",
    "        weights.masked_fill_(bb_mask_crossed, 0.)\n",
    "\n",
    "        coords_3d, _ = MDScaling(distances, \n",
    "            weights = weights,\n",
    "            iters = model.mds_iters,\n",
    "            fix_mirror = True,\n",
    "            N_mask = N_mask,\n",
    "            CA_mask = CA_mask,\n",
    "            C_mask = C_mask\n",
    "        )\n",
    "        pred_coords = rearrange(coords_3d, 'b c n -> b n c')\n",
    "        \n",
    "        ### Stage 3\n",
    "        \n",
    "        # See below for code from EGNN loop:\n",
    "        ## encode as needed\n",
    "        #encoded = encode_whole_protein(seq, true_coords, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        #x, edge_index, edge_attrs, embedd_info = encoded\n",
    "        ## add position coords\n",
    "        #cloud_mask = scn_cloud_mask(seq)\n",
    "        #if padding_seq:\n",
    "        #    cloud_mask[-padding_seq:] = 0.\n",
    "        #cloud_mask = cloud_mask.bool()\n",
    "        #flat_cloud_mask = rearrange(cloud_mask, 'l c -> (l c)')\n",
    "        #x = torch.cat([true_coords[flat_cloud_mask], x ], dim=-1)\n",
    "        \n",
    "        \n",
    "        # We need as shown in line:\n",
    "        # seq, true_coords, angles, padding_seq, mask, pid = get_prot(dataloader_=dataloaders_,\n",
    "        \n",
    "        # From batch \"keys\":\n",
    "        # 'angs', 'count', 'crds', 'evos', 'index', 'int_seqs', 'msks', 'pids', 'ress', 'secs', 'seq_evo_sec', 'seqs'\n",
    "        \n",
    "        # Assume batch dim is 1\n",
    "        true_coords = coords #Â get the coords label from above\n",
    "        angles = batch.angs.to(DEVICE)\n",
    "        seq_str = ''.join([VOCAB.int2char(aa.item()) for aa in seq[0]])\n",
    "        padding_seq = (seq[0] == 20).sum()\n",
    "        #padding_seq = 1\n",
    "        # padding_seq ?\n",
    "        mask = batch.msks.to(DEVICE)\n",
    "        pid = batch.pids #.to(DEVICE)\n",
    "        \n",
    "        # encode as needed\n",
    "        #encoded = encode_whole_protein(seq_str, pred_coords, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        #encoded = encode_whole_protein(seq, pred_coords, angles, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        #pdb.set_trace()\n",
    "        print(f\"len(seq_str): {len(seq_str)}, pred_coords.shape: {pred_coords.shape}, angles.shape: {angles.shape}, padding_seq: {padding_seq}\")\n",
    "        encoded = encode_whole_protein(seq_str, pred_coords[0], angles[0], padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        x, edge_index, edge_attrs, embedd_info = encoded\n",
    "        \n",
    "        # add position coords - better mask accounting for missing atoms\n",
    "        cloud_mask_naive = scn_cloud_mask(seq_str).bool()\n",
    "        cloud_mask = scn_cloud_mask(seq_str, coords=true_coords).bool()\n",
    "        if padding_seq:\n",
    "            cloud_mask[-padding_seq:] = 0.\n",
    "        # cloud is all points, chain is all for which we have labels\n",
    "        chain_mask = mask.unsqueeze(-1) * cloud_mask\n",
    "        flat_chain_mask = rearrange(chain_mask, 'l c -> (l c)')\n",
    "        flat_cloud_mask = rearrange(cloud_mask, 'l c -> (l c)')\n",
    "        # slice useless norm and vector embeddings\n",
    "        masked_coords = masked_coords[flat_cloud_mask]\n",
    "\n",
    "        #############\n",
    "        # MASK EDGES AND NODES ACCOUNTING FOR SCN MISSING ATOMS\n",
    "        #############\n",
    "        # NODES\n",
    "        x = torch.cat([masked_coords, x[:, -2:][cloud_mask[cloud_mask_naive]] ], dim=-1)\n",
    "        # EDGES: delete all edges with masked-out atoms\n",
    "\n",
    "        # pick all current indexes and turn them to 1.\n",
    "        to_mask_edges = torch.zeros(edge_index.amax()+1, edge_index.amax()+1).to(edge_index.device)\n",
    "        to_mask_edges[edge_index[0], edge_index[1]] = 1.\n",
    "        # delete erased bonds\n",
    "        masked_out_atoms = (-1*(cloud_mask[cloud_mask_naive].float() - 1)).bool()\n",
    "        to_mask_edges[masked_out_atoms] *= 0.\n",
    "        to_mask_edges = to_mask_edges * to_mask_edges.t()\n",
    "        # get mask for the edge_attrs\n",
    "        attr_mask = to_mask_edges[edge_index[0], edge_index[1]].bool()\n",
    "        edge_attrs = edge_attrs[attr_mask, :]\n",
    "        # delete unwanted rows and cols\n",
    "        wanted = to_mask_edges.sum(dim=-1).bool()\n",
    "        edge_index = (to_mask_edges[wanted, :][:, wanted]).nonzero().t()\n",
    "        #############\n",
    "        # continue\n",
    "        #############\n",
    "        edge_attrs = edge_attrs[:, -1:]\n",
    "        batch = torch.tensor([0 for i in range(x.shape[0])], device=device).long()\n",
    "\n",
    "        if torch.amax(edge_index) >= x.shape[0]:\n",
    "            print(\"wtf, breaking, debug, index out of bounds\")\n",
    "            break\n",
    "\n",
    "        # predict\n",
    "        preds = model.forward(x, edge_index, batch=batch, edge_attr=edge_attrs,\n",
    "                              recalc_edge=None, verbose = False)\n",
    "\n",
    "        # MEASURE ERROR - format pred and target\n",
    "        target_coords = true_coords[flat_cloud_mask].clone()\n",
    "        pred_coords   = preds[:, :3]\n",
    "        base_coords   = x[:, :3]\n",
    "\n",
    "        # option 2: loss is RMSD on reconstructed coords  // align - sometimes svc fails - idk why\n",
    "        try:\n",
    "            pred_aligned, target_aligned = kabsch_torch(pred_coords.t(), target_coords.t()) # (3, N)\n",
    "\n",
    "            loss = ( (pred_aligned.t() - target_aligned.t())[flat_chain_mask[flat_cloud_mask]]**2 ).mean() \n",
    "        except:\n",
    "            pred_aligned, target_aligned = None, None\n",
    "            print(\"svd failed convergence, ep:\", ep)\n",
    "            loss = ( (pred_coords - target_coords)[flat_chain_mask[flat_cloud_mask]]**2 ).mean()\n",
    "        # measure error\n",
    "        loss_base = ((base_coords - target_coords)**2).mean() \n",
    "        # not aligned: # loss = ((pred_coords - target_coords)**2).mean()**0.5 \n",
    "\n",
    "        # back pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # records / prints\n",
    "        iteration += 1\n",
    "        epoch_losses.append( loss.item() )\n",
    "        baseline_losses.append( loss_base.item() )\n",
    "\n",
    "        n_print = 10\n",
    "        if iteration % n_print == 1:\n",
    "            tic = time.time()\n",
    "            print(\"BATCH: {0} / {1}, loss: {2}, baseline_loss: {3}, time: {4}\".format(iteration, n_per_iter,\n",
    "                                                                                      np.mean(epoch_losses[-n_print:]),\n",
    "                                                                                      baseline_losses[-1],\n",
    "                                                                                      tic-tac))\n",
    "            tac = time.time()\n",
    "            if iteration % n_per_iter == 1:\n",
    "                print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "confidential-contamination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:58:25.540094Z",
     "start_time": "2021-04-02T10:58:25.534537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.42857142857143"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "468/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "biblical-proportion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:58:31.124068Z",
     "start_time": "2021-04-02T10:58:31.115147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-momentum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "welsh-brunswick",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:49:11.459839Z",
     "start_time": "2021-04-02T10:47:51.173543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m(376)\u001b[0;36mreduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    374 \u001b[0;31m            \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n Input is list. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    375 \u001b[0;31m        \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'Additional info: {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 376 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    377 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    378 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m(424)\u001b[0;36mrearrange\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    422 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rearrange can't be applied to an empty list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    423 \u001b[0;31m        \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_on_zeroth_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 424 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rearrange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    425 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    426 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/mmp/projects/EleutherAI/geometric-vector-perceptron/examples/data_utils.py\u001b[0m(536)\u001b[0;36mencode_whole_protein\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    534 \u001b[0;31m    \u001b[0mpos_unit_norms_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_unit_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneeded_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"atom_pos_scales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    535 \u001b[0;31m    \u001b[0;31m# reformat coordinates to scn (L, 14, 3) - TODO: solve if padding=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 536 \u001b[0;31m    \u001b[0mcoords_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(l c) d -> l c d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpadding_seq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    537 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    538 \u001b[0;31m    \u001b[0;31m# position in backbone embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> center_coords.shape\n",
      "torch.Size([1, 375, 3])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "preceding-mexican",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T10:00:49.348668Z",
     "start_time": "2021-04-02T10:00:49.343111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.214285714285715"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "633/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-there",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spatial-wound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:58.860910Z",
     "start_time": "2021-03-30T19:15:58.783068Z"
    }
   },
   "outputs": [],
   "source": [
    "??Alphafold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "substantial-aurora",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:42.262755Z",
     "start_time": "2021-03-30T19:15:42.257525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alphafold2_pytorch.alphafold2.Alphafold2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acoustic-consistency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:29.356150Z",
     "start_time": "2021-03-30T19:15:29.350419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_backbone_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-growth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:58:04.574746Z",
     "start_time": "2021-03-30T18:57:44.749Z"
    }
   },
   "outputs": [],
   "source": [
    "        ### Old stuff:\n",
    "\n",
    "#        # build SC container. set SC points to CA and optionally place carbonyl O\n",
    "#        proto_sidechain = sidechain_container(refined, n_aa=batch,\n",
    "#                                              cloud_mask=cloud_mask, place_oxygen=False)\n",
    "#\n",
    "#        # rotate / align\n",
    "#        coords_aligned, labels_aligned = Kabsch(refined, coords[flat_cloud_mask])\n",
    "#\n",
    "#        # atom mask\n",
    "#\n",
    "#        cloud_mask = scn_cloud_mask(seq, boolean = False)\n",
    "#        flat_cloud_mask = rearrange(cloud_mask, 'b l c -> b (l c)')\n",
    "#\n",
    "#        # chain_mask is all atoms that will be backpropped thru -> existing + trainable\n",
    "#\n",
    "#        chain_mask = (mask * cloud_mask)[cloud_mask]\n",
    "#        flat_chain_mask = rearrange(chain_mask, 'b l c -> b (l c)')\n",
    "#\n",
    "#        # save pdb files for visualization\n",
    "#\n",
    "#        if TO_PDB:\n",
    "#            # idx from batch to save prot and label\n",
    "#            idx = 0\n",
    "#            coords2pdb(seq[idx, :, 0], coords_aligned[idx], cloud_mask, prefix=SAVE_DIR, name=\"pred.pdb\")\n",
    "#            coords2pdb(seq[idx, :, 0], labels_aligned[idx], cloud_mask, prefix=SAVE_DIR, name=\"label.pdb\")\n",
    "#\n",
    "#        # loss - RMSE + distogram_dispersion\n",
    "#        loss = torch.sqrt(criterion(coords_aligned[flat_chain_mask], labels_aligned[flat_chain_mask])) + \\\n",
    "#                          dispersion_weight * torch.norm( (1/weights)-1 )\n",
    "#\n",
    "#        loss.backward()\n",
    "#    print('loss:', loss.item())\n",
    "#\n",
    "#    optim.step()\n",
    "#    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-provincial",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphafold2_pytorch",
   "language": "python",
   "name": "alphafold2_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
