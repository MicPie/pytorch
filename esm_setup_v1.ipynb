{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-sense",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-coupon",
   "metadata": {},
   "source": [
    "Based on https://github.com/lucidrains/alphafold2 and https://github.com/lucidrains/egnn-pytorch with help from https://github.com/hypnopump."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-endorsement",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "divided-advocacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:49.843973Z",
     "start_time": "2021-04-02T08:42:49.322670Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "neither-avatar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T09:26:26.979524Z",
     "start_time": "2021-04-02T09:26:26.973591Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-vatican",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compact-gates",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:50.384153Z",
     "start_time": "2021-04-02T08:42:49.846405Z"
    }
   },
   "outputs": [],
   "source": [
    "import sidechainnet as scn\n",
    "#from sidechainnet.sequence.utils import VOCAB\n",
    "from sidechainnet.utils.sequence import ProteinVocabulary as VOCAB # From https://github.com/lucidrains/egnn-pytorch/blob/main/examples/egnn_test.ipynb\n",
    "VOCAB = VOCAB()\n",
    "from sidechainnet.structure.build_info import NUM_COORDS_PER_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "italic-spyware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:50.391746Z",
     "start_time": "2021-04-02T08:42:50.385414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinVocabulary[size=21]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-split",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:34.529141Z",
     "start_time": "2021-03-27T11:16:34.449068Z"
    }
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funny-tomato",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:50.471689Z",
     "start_time": "2021-04-02T08:42:50.392722Z"
    }
   },
   "outputs": [],
   "source": [
    "from alphafold2_pytorch import Alphafold2\n",
    "import alphafold2_pytorch.constants as constants\n",
    "\n",
    "from se3_transformer_pytorch import SE3Transformer\n",
    "from alphafold2_pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-newcastle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:34.606712Z",
     "start_time": "2021-03-27T11:16:34.599228Z"
    }
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "painted-rogers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:50.475569Z",
     "start_time": "2021-04-02T08:42:50.472959Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = \"esm\" # one of [\"esm\", \"msa\", None]\n",
    "DEVICE = None # defaults to cuda if available, else cpu\n",
    "NUM_BATCHES = int(1e5)\n",
    "GRADIENT_ACCUMULATE_EVERY = 1 #16\n",
    "LEARNING_RATE = 3e-4\n",
    "IGNORE_INDEX = -100\n",
    "THRESHOLD_LENGTH = 250\n",
    "TO_PDB = False\n",
    "SAVE_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reduced-criterion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:50.776080Z",
     "start_time": "2021-04-02T08:42:50.769825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('esm', None, 100000, 1, 0.0003, -100, 250, False, '')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES, DEVICE, NUM_BATCHES, GRADIENT_ACCUMULATE_EVERY, LEARNING_RATE, IGNORE_INDEX, THRESHOLD_LENGTH, TO_PDB, SAVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-chicken",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:35.274958Z",
     "start_time": "2021-03-27T11:16:35.268764Z"
    }
   },
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "average-marks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:51.354335Z",
     "start_time": "2021-04-02T08:42:51.348434Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = constants.DEVICE\n",
    "DISTOGRAM_BUCKETS = constants.DISTOGRAM_BUCKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forced-grass",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:42:51.624855Z",
     "start_time": "2021-04-02T08:42:51.619329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), 37)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE, DISTOGRAM_BUCKETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-dinner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:44.738347Z",
     "start_time": "2021-03-27T11:16:35.993046Z"
    }
   },
   "source": [
    "# Set embedder model from esm if appropiate - Load ESM-1b model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "varying-mathematics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:00.943856Z",
     "start_time": "2021-04-02T08:42:52.126605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mmp/.cache/torch/hub/facebookresearch_esm_master\n"
     ]
    }
   ],
   "source": [
    "if FEATURES == \"esm\":\n",
    "    # from pytorch hub (almost 30gb)\n",
    "    embedd_model, alphabet = torch.hub.load(\"facebookresearch/esm\", \"esm1b_t33_650M_UR50S\")\n",
    "    ##  alternatively do\n",
    "    # import esm # after installing esm\n",
    "    # model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "    batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-matter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:22:10.874606Z",
     "start_time": "2021-03-27T11:22:10.869292Z"
    }
   },
   "source": [
    "# AF2 helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggregate-collectible",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:00.948928Z",
     "start_time": "2021-04-02T08:43:00.945113Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle(loader, cond = lambda x: True):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            if not cond(data):\n",
    "                continue\n",
    "            yield data\n",
    "\n",
    "def get_esm_embedd(seq):\n",
    "    str_seq = \"\".join([VOCAB.int2char(x) for x in seq.squeeze(0).cpu().numpy()])\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter( [(0, str_seq)] )\n",
    "    with torch.no_grad():\n",
    "        results = embedd_model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    return results[\"representations\"][33].to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-power",
   "metadata": {},
   "source": [
    "https://github.com/jonathanking/sidechainnet#loading-sidechainnet-with-pytorch-dataloaders<br>\n",
    "`Downloaded SidechainNet to ./sidechainnet_data/sidechainnet_casp12_30.pkl.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-disposal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:48.960650Z",
     "start_time": "2021-03-27T11:16:44.744531Z"
    }
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "capital-exchange",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:05.798985Z",
     "start_time": "2021-04-02T08:43:00.950215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp12_30.pkl.\n"
     ]
    }
   ],
   "source": [
    "data = scn.load(\n",
    "    casp_version = 12,\n",
    "    thinning = 30,\n",
    "    with_pytorch = 'dataloaders',\n",
    "    batch_size = 1,\n",
    "    dynamic_batching = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceramic-image",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:05.802874Z",
     "start_time": "2021-04-02T08:43:05.800363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'train-eval', 'test', 'valid-10', 'valid-20', 'valid-30', 'valid-40', 'valid-50', 'valid-70', 'valid-90'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "foster-literacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:05.924696Z",
     "start_time": "2021-04-02T08:43:05.803772Z"
    }
   },
   "outputs": [],
   "source": [
    "data = iter(data['train'])\n",
    "data_cond = lambda t: t[1].shape[1] < THRESHOLD_LENGTH\n",
    "dl = cycle(data, data_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "incoming-syndication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:05.928878Z",
     "start_time": "2021-04-02T08:43:05.926562Z"
    }
   },
   "outputs": [],
   "source": [
    "#d_test = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "little-response",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:05.933803Z",
     "start_time": "2021-04-02T08:43:05.930206Z"
    }
   },
   "outputs": [],
   "source": [
    "#dir(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recorded-johnston",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:05.938379Z",
     "start_time": "2021-04-02T08:43:05.935686Z"
    }
   },
   "outputs": [],
   "source": [
    "# d_test \"keys\": 'angs', 'count', 'crds', 'evos', 'index', 'int_seqs',\n",
    "#                'msks', 'pids', 'ress', 'secs', 'seq_evo_sec', 'seqs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-deployment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:54.778596Z",
     "start_time": "2021-03-27T11:16:49.083056Z"
    }
   },
   "source": [
    "# AF2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "placed-abortion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.680809Z",
     "start_time": "2021-04-02T08:43:05.939736Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Alphafold2(\n",
    "    dim = 128,\n",
    "    depth = 1,\n",
    "    heads = 1, # Maybe set even lower?\n",
    "    dim_head = 16, # Maybe set even lower?\n",
    "    predict_coords = False,\n",
    "    num_backbone_atoms = 3,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fancy-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.683479Z",
     "start_time": "2021-04-02T08:43:09.681959Z"
    }
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-greenhouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:16:54.795251Z",
     "start_time": "2021-03-27T11:16:54.782721Z"
    }
   },
   "source": [
    "# AF2 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "northern-horror",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.697190Z",
     "start_time": "2021-04-02T08:43:09.684406Z"
    }
   },
   "outputs": [],
   "source": [
    "dispersion_weight = 0.1\n",
    "criterion = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-cambodia",
   "metadata": {},
   "source": [
    "# EGNN helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-radar",
   "metadata": {},
   "source": [
    "Based on: https://github.com/lucidrains/egnn-pytorch/blob/main/examples/egnn_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "insured-disposal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.706648Z",
     "start_time": "2021-04-02T08:43:09.698355Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_whole_protein(seq, true_coords, padding_seq,\n",
    "                         needed_info = { \"cutoffs\": [2, 5, 10],\n",
    "                                          \"bond_scales\": [0.5, 1, 2]}, free_mem=False):\n",
    "    \"\"\" Encodes a whole protein. In points + vectors. \"\"\"\n",
    "    device, precise = true_coords.device, true_coords.type()\n",
    "    #################\n",
    "    # encode points #\n",
    "    #################\n",
    "    cloud_mask = torch.tensor(scn_cloud_mask(seq[:-padding_seq or None])).bool().to(device)\n",
    "    flat_mask = rearrange(cloud_mask, 'l c -> (l c)')\n",
    "    coords_wrap = rearrange(true_coords, '(l c) d -> l c d', c=14)[:-padding_seq or None] \n",
    "    # embedd everything\n",
    "\n",
    "    # position in backbone embedding\n",
    "    aa_pos = encode_dist( torch.arange(len(seq[:-padding_seq or None]), device=device).float(), scales=needed_info[\"aa_pos_scales\"])\n",
    "    atom_pos = chain2atoms(aa_pos)[cloud_mask]\n",
    "\n",
    "    # atom identity embedding\n",
    "    atom_id_embedds = torch.stack([SUPREME_INFO[k][\"atom_id_embedd\"] for k in seq[:-padding_seq or None]], \n",
    "                                  dim=0)[cloud_mask].to(device)\n",
    "    # aa embedding\n",
    "    seq_int = torch.tensor([AAS2NUM[aa] for aa in seq[:-padding_seq or None]], device=device).long()\n",
    "    aa_id_embedds   = chain2atoms(seq_int, mask=cloud_mask)\n",
    "\n",
    "    ################\n",
    "    # encode bonds #\n",
    "    ################\n",
    "    bond_info = encode_whole_bonds(x = coords_wrap[cloud_mask],\n",
    "                                   x_format = \"coords\",\n",
    "                                   embedd_info = {},\n",
    "                                   needed_info = needed_info )\n",
    "    whole_bond_idxs, whole_bond_enc, bond_embedd_info = bond_info\n",
    "    #########\n",
    "    # merge #\n",
    "    #########\n",
    "\n",
    "    # concat so that final is [vector_dims, scalar_dims]\n",
    "    point_n_vectors = 0\n",
    "    point_n_scalars = 2*len(needed_info[\"aa_pos_scales\"]) + 1 +\\\n",
    "                      2 # the last 2 are to be embedded yet\n",
    "\n",
    "    whole_point_enc = torch.cat([ atom_pos, # 2n+1\n",
    "                                  atom_id_embedds.unsqueeze(-1),\n",
    "                                  aa_id_embedds.unsqueeze(-1) ], dim=-1) # the last 2 are yet to be embedded\n",
    "    if free_mem:\n",
    "        del cloud_mask, atom_pos, atom_id_embedds, aa_id_embedds\n",
    "\n",
    "    # record embedding dimensions\n",
    "    point_embedd_info = {\"point_n_vectors\": point_n_vectors,\n",
    "                         \"point_n_scalars\": point_n_scalars,}\n",
    "\n",
    "    embedd_info = {**point_embedd_info, **bond_embedd_info}\n",
    "\n",
    "    return whole_point_enc, whole_bond_idxs, whole_bond_enc, embedd_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "possible-stocks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.714150Z",
     "start_time": "2021-04-02T08:43:09.707597Z"
    }
   },
   "outputs": [],
   "source": [
    "NEEDED_INFO = {\"cutoffs\": [], # \"15_closest\"\n",
    "               \"bond_scales\": [1, 2],\n",
    "               \"aa_pos_scales\": [2,4,8,16,32,64,128],\n",
    "               \"atom_pos_scales\": [1,2,4,8,16,32],\n",
    "               \"dist2ca_norm_scales\": [1,2,4],\n",
    "               \"bb_norms_atoms\": [0.5], # will encode 3 vectors with this\n",
    "               # nn-degree connection\n",
    "               \"adj_degree\": 2\n",
    "              }\n",
    "# get model sizes from encoded protein\n",
    "#seq, true_coords, angles, padding_seq, mask, id = train_examples_storer[-1] \n",
    "#NEEDED_INFO[\"seq\"] = seq[:-padding_seq or None]\n",
    "#NEEDED_INFO[\"covalent_bond\"] = prot_covalent_bond(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elder-papua",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.719319Z",
     "start_time": "2021-04-02T08:43:09.715155Z"
    }
   },
   "outputs": [],
   "source": [
    "### adjust for egnn: \n",
    "#embedd_info[\"bond_n_scalars\"] -= 2*len(NEEDED_INFO[\"bond_scales\"])+1\n",
    "#embedd_info[\"bond_n_vectors\"] = 0\n",
    "#embedd_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expensive-advance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.726972Z",
     "start_time": "2021-04-02T08:43:09.720407Z"
    }
   },
   "outputs": [],
   "source": [
    "def prot_covalent_bond(seq, adj_degree=1, cloud_mask=None):\n",
    "    \"\"\" Returns the idxs of covalent bonds for a protein.\n",
    "        Inputs \n",
    "        * seq: str. Protein sequence in 1-letter AA code.\n",
    "        * cloud_mask: mask selecting the present atoms.\n",
    "        Outputs: edge_idxs\n",
    "    \"\"\"\n",
    "    # create or infer cloud_mask\n",
    "    if cloud_mask is None: \n",
    "        cloud_mask = scn_cloud_mask(seq).bool()\n",
    "    device, precise = cloud_mask.device, cloud_mask.type()\n",
    "    # get starting poses for every aa\n",
    "    scaff = torch.zeros_like(cloud_mask)\n",
    "    scaff[:, 0] = 1\n",
    "    idxs = scaff[cloud_mask].nonzero().view(-1)\n",
    "    # get poses + idxs from the dict with GVP_DATA - return all edges\n",
    "    adj_mat = torch.zeros(idxs.amax()+14, idxs.amax()+14)\n",
    "    attr_mat = torch.zeros_like(adj_mat)\n",
    "    for i,idx in enumerate(idxs):\n",
    "        # bond with next aa\n",
    "        extra = []\n",
    "        if i < idxs.shape[0]-1:\n",
    "            extra = [[2, (idxs[i+1]-idx).item()]]\n",
    "\n",
    "        bonds = idx + torch.tensor( GVP_DATA[seq[i]]['bonds'] + extra ).long().t() \n",
    "        adj_mat[bonds[0], bonds[1]] = 1.\n",
    "\n",
    "    # convert to undirected\n",
    "    adj_mat = adj_mat + adj_mat.t()\n",
    "    # do N_th degree adjacency\n",
    "    for i in range(adj_degree):\n",
    "        if i == 0:\n",
    "            attr_mat += adj_mat\n",
    "            continue\n",
    "\n",
    "        adj_mat = (adj_mat @ adj_mat).bool().float() \n",
    "        attr_mat[ (adj_mat - attr_mat.bool().float()).bool() ] += i+1\n",
    "\n",
    "    edge_idxs = attr_mat.nonzero().t().long()\n",
    "    edge_attrs = attr_mat[edge_idxs[0], edge_idxs[1]]\n",
    "\n",
    "    return edge_idxs, edge_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-diameter",
   "metadata": {},
   "source": [
    "# EGNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "worth-expansion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:09.733681Z",
     "start_time": "2021-04-02T08:43:09.728027Z"
    }
   },
   "outputs": [],
   "source": [
    "#from egnn_pytorch.egnn_pytorch import EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "julian-calvin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T09:26:37.232211Z",
     "start_time": "2021-04-02T09:26:37.225509Z"
    }
   },
   "outputs": [],
   "source": [
    "os.sys.path.append('/home/mmp/projects/EleutherAI/egnn_pytorch_git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "selected-passage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T09:29:51.210936Z",
     "start_time": "2021-04-02T09:29:50.757130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoise_sparse.py  \u001b[0m\u001b[01;34megnn_pytorch_git\u001b[0m/  LICENSE    setup.cfg  \u001b[01;34mtests\u001b[0m/\r\n",
      "\u001b[01;35megnn.png\u001b[0m           \u001b[01;34mexamples\u001b[0m/          README.md  setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/mmp/projects/EleutherAI/egnn_pytorch_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "religious-camcorder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:11.234363Z",
     "start_time": "2021-04-02T08:43:09.740003Z"
    }
   },
   "outputs": [],
   "source": [
    "from egnn_pytorch_git.egnn_pytorch_git import EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "front-coordinator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:11.243272Z",
     "start_time": "2021-04-02T08:43:11.235494Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model_egnn = EGNN_Sparse_Network(n_layers=4,\n",
    "                                 feats_dim=2,\n",
    "                                 pos_dim = 3,\n",
    "                                 edge_attr_dim = 1,\n",
    "                                 m_dim = 32,\n",
    "                                 fourier_features = 4,\n",
    "                                 embedding_nums=[36,20],\n",
    "                                 embedding_dims=[16,16],\n",
    "                                 edge_embedding_nums=[3],\n",
    "                                 edge_embedding_dims=[2],\n",
    "                                 update_coors=True,\n",
    "                                 update_feats=True, \n",
    "                                 norm_feats=False,\n",
    "                                 norm_coors=False,\n",
    "                                 recalc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "harmful-victory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:11.246973Z",
     "start_time": "2021-04-02T08:43:11.244203Z"
    }
   },
   "outputs": [],
   "source": [
    "#??EGNN_Sparse_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "appreciated-march",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:11.263471Z",
     "start_time": "2021-04-02T08:43:11.247959Z"
    }
   },
   "outputs": [],
   "source": [
    "model_egnn = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "described-netherlands",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:11.276762Z",
     "start_time": "2021-04-02T08:43:11.264455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/torch/optim/adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam( list(model_egnn.parameters()) + \\\n",
    "                              list(model.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-officer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T19:19:56.343261Z",
     "start_time": "2021-03-27T19:19:55.635175Z"
    }
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "strategic-philip",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T08:43:12.165126Z",
     "start_time": "2021-04-02T08:43:11.278586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0, stress tensor([4758.6426], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 1, stress tensor([5778.1367], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 2, stress tensor([5723.7520], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 3, stress tensor([5723.3672], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "it: 4, stress tensor([5723.3232], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Corrected mirror idxs: tensor([], dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"l c -> (l c)\".\n Input tensor shape: torch.Size([1, 141, 14]). Additional info: {}.\n Expected 2 dimensions, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mrecipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_transformation_recipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashable_axes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEinopsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    204\u001b[0m         init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes = self.reconstruct_from_shape(\n\u001b[0;32m--> 205\u001b[0;31m             backend.shape(tensor))\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreconstruct_from_shape\u001b[0;34m(self, shape, optimize)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected {} dimensions, got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mknown_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munknown_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEinopsError\u001b[0m: Expected 2 dimensions, got 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5d32a8248245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# encode as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m#encoded = encode_whole_protein(seq_str, pred_coords, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_whole_protein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeded_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEEDED_INFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_mem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-9d272457c9fe>\u001b[0m in \u001b[0;36mencode_whole_protein\u001b[0;34m(seq, true_coords, padding_seq, needed_info, free_mem)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcloud_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscn_cloud_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpadding_seq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mflat_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l c -> (l c)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mcoords_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(l c) d -> l c d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpadding_seq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# embedd everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rearrange can't be applied to an empty list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_on_zeroth_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rearrange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n Input is list. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'Additional info: {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"l c -> (l c)\".\n Input tensor shape: torch.Size([1, 141, 14]). Additional info: {}.\n Expected 2 dimensions, got 3"
     ]
    }
   ],
   "source": [
    "for _ in range(NUM_BATCHES):\n",
    "    for _ in range(GRADIENT_ACCUMULATE_EVERY):\n",
    "        \n",
    "        ### Stage 1\n",
    "        \n",
    "        batch = next(dl)\n",
    "        seq, coords, mask = batch.seqs, batch.crds, batch.msks\n",
    "        mask = mask.bool() # Needs to be set to bool\n",
    "\n",
    "        b, l, _ = seq.shape\n",
    "\n",
    "        # prepare data and mask labels\n",
    "        seq, coords, mask = seq.argmax(dim = -1).to(DEVICE), coords.to(DEVICE), mask.to(DEVICE)\n",
    "        # coords = rearrange(coords, 'b (l c) d -> b l c d', l = l) # no need to rearrange for now\n",
    "        # mask the atoms and backbone positions for each residue\n",
    "\n",
    "        # sequence embedding (msa / esm / attn / or nothing)\n",
    "        msa, embedds = None, None\n",
    "\n",
    "        # get embedds\n",
    "        if FEATURES == \"esm\":\n",
    "            #embedds = get_esm_embedd(seq)\n",
    "            embedds = get_esm_embedd(seq).unsqueeze(0)\n",
    "            msa_mask = None\n",
    "            #msa_mask = torch.ones_like(embedds).bool()\n",
    "            #msa_mask = torch.ones_like(embedds[..., -1]).bool()\n",
    "        # get msa here\n",
    "        elif FEATURES == \"msa\":\n",
    "            pass\n",
    "        # no embeddings\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # predict - out is (batch, L * 3, 3)\n",
    "\n",
    "        refined = model(\n",
    "            seq,\n",
    "            msa = msa,\n",
    "            embedds = embedds,\n",
    "            mask = mask,\n",
    "            msa_mask = msa_mask\n",
    "            )\n",
    "        \n",
    "        ### Stage 2\n",
    "        \n",
    "        distance_pred = refined # is this correct?\n",
    "        \n",
    "        \n",
    "        # prepare mask for backbone coordinates\n",
    "\n",
    "        assert model.num_backbone_atoms > 1, 'must constitute to at least 3 atomic coordinates for backbone'\n",
    "\n",
    "        N_mask, CA_mask, C_mask = scn_backbone_mask(seq, boolean = True, n_aa = model.num_backbone_atoms)\n",
    "\n",
    "        cloud_mask = scn_cloud_mask(seq, boolean=True)\n",
    "        flat_cloud_mask = rearrange(cloud_mask, 'b l c -> b (l c)')\n",
    "        chain_mask = (mask.unsqueeze(-1) * cloud_mask)\n",
    "        flat_chain_mask = rearrange(chain_mask, 'b l c -> b (l c)')\n",
    "\n",
    "        bb_mask = rearrange(chain_mask[:, :, :model.num_backbone_atoms], 'b l c -> b (l c)')\n",
    "        bb_mask_crossed = rearrange(bb_mask, 'b i -> b i ()') * rearrange(bb_mask, 'b j -> b () j')\n",
    "\n",
    "        # structural refinement\n",
    "\n",
    "        if model.predict_real_value_distances:\n",
    "            distances, distance_std = distance_pred.unbind(dim = -1)\n",
    "            weights = (1 / (1 + distance_std)) # could also do a distance_std.sigmoid() here\n",
    "        else:\n",
    "            distances, weights = center_distogram_torch(distance_pred)\n",
    "\n",
    "        weights.masked_fill_(bb_mask_crossed, 0.)\n",
    "\n",
    "        coords_3d, _ = MDScaling(distances, \n",
    "            weights = weights,\n",
    "            iters = model.mds_iters,\n",
    "            fix_mirror = True,\n",
    "            N_mask = N_mask,\n",
    "            CA_mask = CA_mask,\n",
    "            C_mask = C_mask\n",
    "        )\n",
    "        pred_coords = rearrange(coords_3d, 'b c n -> b n c')\n",
    "        \n",
    "        ### Stage 3\n",
    "        \n",
    "        # See below for code from EGNN loop:\n",
    "        ## encode as needed\n",
    "        #encoded = encode_whole_protein(seq, true_coords, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        #x, edge_index, edge_attrs, embedd_info = encoded\n",
    "        ## add position coords\n",
    "        #cloud_mask = scn_cloud_mask(seq)\n",
    "        #if padding_seq:\n",
    "        #    cloud_mask[-padding_seq:] = 0.\n",
    "        #cloud_mask = cloud_mask.bool()\n",
    "        #flat_cloud_mask = rearrange(cloud_mask, 'l c -> (l c)')\n",
    "        #x = torch.cat([true_coords[flat_cloud_mask], x ], dim=-1)\n",
    "        \n",
    "        \n",
    "        # We need as shown in line:\n",
    "        # seq, true_coords, angles, padding_seq, mask, pid = get_prot(dataloader_=dataloaders_,\n",
    "        \n",
    "        # From batch \"keys\":\n",
    "        # 'angs', 'count', 'crds', 'evos', 'index', 'int_seqs', 'msks', 'pids', 'ress', 'secs', 'seq_evo_sec', 'seqs'\n",
    "        \n",
    "        # Assume batch dim is 1\n",
    "        true_coords = coords # get the coords label from above\n",
    "        angles = batch.angs.to(DEVICE)\n",
    "        seq_str = ''.join([VOCAB.int2char(aa.item()) for aa in seq[0]])\n",
    "        padding_seq = (seq[0] == 20).sum()\n",
    "        # padding_seq ?\n",
    "        mask = batch.msks.to(DEVICE)\n",
    "        pid = batch.pids #.to(DEVICE)\n",
    "        \n",
    "        # encode as needed\n",
    "        #encoded = encode_whole_protein(seq_str, pred_coords, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        encoded = encode_whole_protein(seq[0], pred_coords[0], padding_seq, needed_info=NEEDED_INFO, free_mem=True)\n",
    "        x, edge_index, edge_attrs, embedd_info = encoded\n",
    "        \n",
    "        # add position coords - better mask accounting for missing atoms\n",
    "        cloud_mask_naive = scn_cloud_mask(seq_str).bool()\n",
    "        cloud_mask = scn_cloud_mask(seq_str, coords=true_coords).bool()\n",
    "        if padding_seq:\n",
    "            cloud_mask[-padding_seq:] = 0.\n",
    "        # cloud is all points, chain is all for which we have labels\n",
    "        chain_mask = mask.unsqueeze(-1) * cloud_mask\n",
    "        flat_chain_mask = rearrange(chain_mask, 'l c -> (l c)')\n",
    "        flat_cloud_mask = rearrange(cloud_mask, 'l c -> (l c)')\n",
    "        # slice useless norm and vector embeddings\n",
    "        masked_coords = masked_coords[flat_cloud_mask]\n",
    "\n",
    "        #############\n",
    "        # MASK EDGES AND NODES ACCOUNTING FOR SCN MISSING ATOMS\n",
    "        #############\n",
    "        # NODES\n",
    "        x = torch.cat([masked_coords, x[:, -2:][cloud_mask[cloud_mask_naive]] ], dim=-1)\n",
    "        # EDGES: delete all edges with masked-out atoms\n",
    "\n",
    "        # pick all current indexes and turn them to 1.\n",
    "        to_mask_edges = torch.zeros(edge_index.amax()+1, edge_index.amax()+1).to(edge_index.device)\n",
    "        to_mask_edges[edge_index[0], edge_index[1]] = 1.\n",
    "        # delete erased bonds\n",
    "        masked_out_atoms = (-1*(cloud_mask[cloud_mask_naive].float() - 1)).bool()\n",
    "        to_mask_edges[masked_out_atoms] *= 0.\n",
    "        to_mask_edges = to_mask_edges * to_mask_edges.t()\n",
    "        # get mask for the edge_attrs\n",
    "        attr_mask = to_mask_edges[edge_index[0], edge_index[1]].bool()\n",
    "        edge_attrs = edge_attrs[attr_mask, :]\n",
    "        # delete unwanted rows and cols\n",
    "        wanted = to_mask_edges.sum(dim=-1).bool()\n",
    "        edge_index = (to_mask_edges[wanted, :][:, wanted]).nonzero().t()\n",
    "        #############\n",
    "        # continue\n",
    "        #############\n",
    "        edge_attrs = edge_attrs[:, -1:]\n",
    "        batch = torch.tensor([0 for i in range(x.shape[0])], device=device).long()\n",
    "\n",
    "        if torch.amax(edge_index) >= x.shape[0]:\n",
    "            print(\"wtf, breaking, debug, index out of bounds\")\n",
    "            break\n",
    "\n",
    "        # predict\n",
    "        preds = model.forward(x, edge_index, batch=batch, edge_attr=edge_attrs,\n",
    "                              recalc_edge=None, verbose = False)\n",
    "\n",
    "        # MEASURE ERROR - format pred and target\n",
    "        target_coords = true_coords[flat_cloud_mask].clone()\n",
    "        pred_coords   = preds[:, :3]\n",
    "        base_coords   = x[:, :3]\n",
    "\n",
    "        # option 2: loss is RMSD on reconstructed coords  // align - sometimes svc fails - idk why\n",
    "        try:\n",
    "            pred_aligned, target_aligned = kabsch_torch(pred_coords.t(), target_coords.t()) # (3, N)\n",
    "\n",
    "            loss = ( (pred_aligned.t() - target_aligned.t())[flat_chain_mask[flat_cloud_mask]]**2 ).mean() \n",
    "        except:\n",
    "            pred_aligned, target_aligned = None, None\n",
    "            print(\"svd failed convergence, ep:\", ep)\n",
    "            loss = ( (pred_coords - target_coords)[flat_chain_mask[flat_cloud_mask]]**2 ).mean()\n",
    "        # measure error\n",
    "        loss_base = ((base_coords - target_coords)**2).mean() \n",
    "        # not aligned: # loss = ((pred_coords - target_coords)**2).mean()**0.5 \n",
    "\n",
    "        # back pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # records / prints\n",
    "        iteration += 1\n",
    "        epoch_losses.append( loss.item() )\n",
    "        baseline_losses.append( loss_base.item() )\n",
    "\n",
    "        n_print = 10\n",
    "        if iteration % n_print == 1:\n",
    "            tic = time.time()\n",
    "            print(\"BATCH: {0} / {1}, loss: {2}, baseline_loss: {3}, time: {4}\".format(iteration, n_per_iter,\n",
    "                                                                                      np.mean(epoch_losses[-n_print:]),\n",
    "                                                                                      baseline_losses[-1],\n",
    "                                                                                      tic-tac))\n",
    "            tac = time.time()\n",
    "            if iteration % n_per_iter == 1:\n",
    "                print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "married-stephen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:25:06.735378Z",
     "start_time": "2021-03-30T19:24:45.898348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m(376)\u001b[0;36mreduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    374 \u001b[0;31m            \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n Input is list. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    375 \u001b[0;31m        \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'Additional info: {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 376 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    377 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    378 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/mmp/miniconda3/envs/alphafold2_pytorch/lib/python3.6/site-packages/einops/einops.py\u001b[0m(424)\u001b[0;36mrearrange\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    422 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rearrange can't be applied to an empty list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    423 \u001b[0;31m        \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_on_zeroth_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 424 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rearrange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    425 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    426 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-40-9d272457c9fe>\u001b[0m(10)\u001b[0;36mencode_whole_protein\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      8 \u001b[0;31m    \u001b[0;31m#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m    \u001b[0mcloud_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscn_cloud_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpadding_seq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m    \u001b[0mflat_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l c -> (l c)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m    \u001b[0mcoords_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(l c) d -> l c d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpadding_seq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m    \u001b[0;31m# embedd everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-57-06653b31f6f0>\u001b[0m(115)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    113 \u001b[0;31m        \u001b[0;31m# encode as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0;31m#encoded = encode_whole_protein(seq_str, pred_coords, padding_seq, needed_info=NEEDED_INFO, free_mem=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 115 \u001b[0;31m        \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_whole_protein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeded_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEEDED_INFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_mem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    116 \u001b[0;31m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    117 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> pred_coords.shape\n",
      "torch.Size([1, 114, 3])\n",
      "ipdb> padding_seq.shape\n",
      "torch.Size([])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-number",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-block",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "collaborative-allen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:58.860910Z",
     "start_time": "2021-03-30T19:15:58.783068Z"
    }
   },
   "outputs": [],
   "source": [
    "??Alphafold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cathedral-situation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:42.262755Z",
     "start_time": "2021-03-30T19:15:42.257525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alphafold2_pytorch.alphafold2.Alphafold2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "continuous-illinois",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:15:29.356150Z",
     "start_time": "2021-03-30T19:15:29.350419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_backbone_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-growth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:58:04.574746Z",
     "start_time": "2021-03-30T18:57:44.749Z"
    }
   },
   "outputs": [],
   "source": [
    "        ### Old stuff:\n",
    "\n",
    "#        # build SC container. set SC points to CA and optionally place carbonyl O\n",
    "#        proto_sidechain = sidechain_container(refined, n_aa=batch,\n",
    "#                                              cloud_mask=cloud_mask, place_oxygen=False)\n",
    "#\n",
    "#        # rotate / align\n",
    "#        coords_aligned, labels_aligned = Kabsch(refined, coords[flat_cloud_mask])\n",
    "#\n",
    "#        # atom mask\n",
    "#\n",
    "#        cloud_mask = scn_cloud_mask(seq, boolean = False)\n",
    "#        flat_cloud_mask = rearrange(cloud_mask, 'b l c -> b (l c)')\n",
    "#\n",
    "#        # chain_mask is all atoms that will be backpropped thru -> existing + trainable\n",
    "#\n",
    "#        chain_mask = (mask * cloud_mask)[cloud_mask]\n",
    "#        flat_chain_mask = rearrange(chain_mask, 'b l c -> b (l c)')\n",
    "#\n",
    "#        # save pdb files for visualization\n",
    "#\n",
    "#        if TO_PDB:\n",
    "#            # idx from batch to save prot and label\n",
    "#            idx = 0\n",
    "#            coords2pdb(seq[idx, :, 0], coords_aligned[idx], cloud_mask, prefix=SAVE_DIR, name=\"pred.pdb\")\n",
    "#            coords2pdb(seq[idx, :, 0], labels_aligned[idx], cloud_mask, prefix=SAVE_DIR, name=\"label.pdb\")\n",
    "#\n",
    "#        # loss - RMSE + distogram_dispersion\n",
    "#        loss = torch.sqrt(criterion(coords_aligned[flat_chain_mask], labels_aligned[flat_chain_mask])) + \\\n",
    "#                          dispersion_weight * torch.norm( (1/weights)-1 )\n",
    "#\n",
    "#        loss.backward()\n",
    "#    print('loss:', loss.item())\n",
    "#\n",
    "#    optim.step()\n",
    "#    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-provincial",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphafold2_pytorch",
   "language": "python",
   "name": "alphafold2_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
